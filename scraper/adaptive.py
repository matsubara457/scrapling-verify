"""Adaptive ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

Scraplingã® Adaptive æ©Ÿèƒ½ã‚’æ¤œè¨¼ã™ã‚‹ã€‚
Phase1: v1ã®HTMLã§auto_save=Trueã«ã‚ˆã‚Šè¦ç´ ã®æŒ‡ç´‹ã‚’ä¿å­˜
Phase2: v2ã®HTMLã§adaptive=Trueã«ã‚ˆã‚Šå¾©å…ƒï¼ˆBS4ã¨ã®æ¯”è¼ƒã‚ã‚Šï¼‰
"""

import json
import os
import sys
import time

import requests
from bs4 import BeautifulSoup
from scrapling.core.storage import SQLiteStorageSystem
from scrapling.fetchers import Fetcher
from scrapling.parser import Selector

BASE_URL = "http://localhost:5001"
DATA_DIR = os.path.join(os.path.dirname(__file__), "..", "data")
STORAGE_FILE = os.path.join(os.path.dirname(__file__), "..", "data", "elements_storage.db")

SELECTORS = [
    (".product-name", "å•†å“å"),
    (".product-price", "ä¾¡æ ¼"),
    (".product-rating", "è©•ä¾¡"),
    (".product-category", "ã‚«ãƒ†ã‚´ãƒª"),
    (".product-desc", "èª¬æ˜"),
]


def clear_storage():
    """Adaptive ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚’ã‚¯ãƒªã‚¢ã™ã‚‹"""
    if os.path.exists(STORAGE_FILE):
        os.remove(STORAGE_FILE)
        print("ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸ")


def phase1_save(url: str = BASE_URL) -> dict:
    """v1ã®HTMLã§è¦ç´ ã®æŒ‡ç´‹ã‚’ä¿å­˜ã™ã‚‹"""
    v1_url = f"{url}?v=v1"
    page = Fetcher.get(v1_url)
    html = page.html_content

    selector = Selector(
        html,
        url=url,
        adaptive=True,
        storage=SQLiteStorageSystem,
        storage_args={"storage_file": STORAGE_FILE, "url": url},
    )

    results = {}
    for css, label in SELECTORS:
        found = selector.css(css, auto_save=True)
        if found:
            results[label] = found[0].text.strip()
            print(f"  ä¿å­˜: {label} ({css}) â†’ ã€Œ{results[label]}ã€")
        else:
            results[label] = None
            print(f"  æœªæ¤œå‡º: {label} ({css})")

    return results


def phase2_restore(url: str = BASE_URL) -> dict:
    """v2ã®HTMLã§adaptiveå¾©å…ƒã‚’è©¦ã¿ã‚‹ï¼ˆBS4ã¨ã®æ¯”è¼ƒã‚ã‚Šï¼‰"""
    v2_url = f"{url}?v=v2"
    page = Fetcher.get(v2_url)
    html = page.html_content

    # BS4ã§v1ã‚»ãƒ¬ã‚¯ã‚¿ã‚’è©¦è¡Œ
    print("[BS4ã§v1ã‚»ãƒ¬ã‚¯ã‚¿ã‚’è©¦è¡Œ]")
    bs4_results = _bs4_check(html)

    # Scrapling Adaptiveã§å¾©å…ƒ
    print("\n[Scrapling Adaptiveã§å¾©å…ƒ]")
    selector = Selector(
        html,
        url=url,
        adaptive=True,
        storage=SQLiteStorageSystem,
        storage_args={"storage_file": STORAGE_FILE, "url": url},
    )

    scrapling_results = {}
    for css, label in SELECTORS:
        found = selector.css(css, adaptive=True)
        if found:
            el = found[0]
            scrapling_results[label] = {
                "text": el.text.strip(),
                "tag": el.tag,
                "class": el.attrib.get("class", ""),
                "original_selector": css,
                "status": "restored",
            }
            print(f"  å¾©å…ƒæˆåŠŸ: {label} ({css}) â†’ <{el.tag} class=\"{el.attrib.get('class', '')}\"> ã€Œ{el.text.strip()}ã€")
        else:
            scrapling_results[label] = {
                "status": "not_found",
                "original_selector": css,
            }
            print(f"  å¾©å…ƒå¤±æ•—: {label} ({css})")

    return {"bs4": bs4_results, "scrapling": scrapling_results}


def _bs4_check(html: str) -> dict:
    """BS4ã§v1ã®ã‚»ãƒ¬ã‚¯ã‚¿ã‚’è©¦è¡Œã—ã€ãƒ’ãƒƒãƒˆæ•°ã‚’è¿”ã™"""
    soup = BeautifulSoup(html, "html.parser")
    results = {}
    for css, label in SELECTORS:
        class_name = css.lstrip(".")
        count = len(soup.find_all(class_=class_name))
        results[label] = count
        status = f"âœ… {count}ä»¶" if count > 0 else "ğŸ’¥ 0ä»¶"
        print(f"  BS4: {label} ({css}) â†’ {status}")
    return results


def run_full_demo(url: str = BASE_URL) -> dict:
    """ãƒ•ãƒ«ãƒ‡ãƒ¢: ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚¯ãƒªã‚¢ â†’ v1ä¿å­˜ â†’ v2å¾©å…ƒ â†’ æ¯”è¼ƒ"""
    print("=" * 50)
    print("Adaptive Scraping ãƒ•ãƒ«ãƒ‡ãƒ¢")
    print("=" * 50)

    # ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚¯ãƒªã‚¢
    print("\n--- ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚¯ãƒªã‚¢ ---")
    clear_storage()

    # Phase1: v1ã§ä¿å­˜
    print(f"\n--- Phase 1: v1ã§æŒ‡ç´‹ä¿å­˜ ---")
    v1_results = phase1_save(url)

    # Phase2: v2ã§å¾©å…ƒ
    print(f"\n--- Phase 2: v2ã§Adaptiveå¾©å…ƒ ---")
    v2_results = phase2_restore(url)

    # çµæœã‚’ã¾ã¨ã‚ã¦ä¿å­˜
    result = {
        "v1_save": v1_results,
        "v2_bs4": v2_results["bs4"],
        "v2_scrapling": v2_results["scrapling"],
    }

    filepath = os.path.join(DATA_DIR, "adaptive_result.json")
    os.makedirs(os.path.dirname(filepath), exist_ok=True)
    with open(filepath, "w", encoding="utf-8") as f:
        json.dump(result, f, ensure_ascii=False, indent=2)
    print(f"\nçµæœã‚’ä¿å­˜: {filepath}")

    # ã‚µãƒãƒª
    bs4_found = sum(1 for v in v2_results["bs4"].values() if v > 0)
    scrapling_found = sum(
        1 for v in v2_results["scrapling"].values()
        if isinstance(v, dict) and v.get("status") == "restored"
    )
    print(f"\n{'=' * 50}")
    print(f"çµæœã‚µãƒãƒª:")
    print(f"  BS4 (v1ã‚»ãƒ¬ã‚¯ã‚¿ â†’ v2):       {bs4_found}/{len(SELECTORS)} ä»¶æ¤œå‡º")
    print(f"  Scrapling Adaptive (å¾©å…ƒ):    {scrapling_found}/{len(SELECTORS)} ä»¶å¾©å…ƒ")
    print(f"{'=' * 50}")

    return result


def run_full_demo_realtime(url: str = BASE_URL) -> dict:
    """ãƒ•ãƒ«ãƒ‡ãƒ¢ï¼ˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡ºåŠ›ç‰ˆï¼‰â€” ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰é€£æºç”¨"""
    # å…¨ã‚¹ãƒ†ãƒƒãƒ—æ•°: ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚¯ãƒªã‚¢(1) + Phase1ä¿å­˜(5) + Phase2 BS4(5) + Phase2å¾©å…ƒ(5) + ä¿å­˜(1) = 17
    total = 1 + len(SELECTORS) * 3 + 1
    current = 0

    # ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚¯ãƒªã‚¢
    print("[STEP] ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚¯ãƒªã‚¢", flush=True)
    clear_storage()
    current += 1
    print(f"[PROGRESS] {current}/{total}", flush=True)

    # Phase1: v1ã§æŒ‡ç´‹ä¿å­˜
    print("[PHASE] Phase1: v1ã§æŒ‡ç´‹ä¿å­˜", flush=True)
    v1_url = f"{url}?v=v1"
    page = Fetcher.get(v1_url)
    html = page.html_content

    selector = Selector(
        html, url=url, adaptive=True,
        storage=SQLiteStorageSystem,
        storage_args={"storage_file": STORAGE_FILE, "url": url},
    )

    v1_results = {}
    for css, label in SELECTORS:
        found = selector.css(css, auto_save=True)
        if found:
            v1_results[label] = found[0].text.strip()
            print(f"[SAVE] {label} ({css}) â†’ ã€Œ{v1_results[label]}ã€", flush=True)
        else:
            v1_results[label] = None
            print(f"[MISS] {label} ({css}) â†’ æœªæ¤œå‡º", flush=True)
        current += 1
        print(f"[PROGRESS] {current}/{total}", flush=True)
        time.sleep(0.3)

    # Phase2: v2ã§Adaptiveå¾©å…ƒ
    print("[PHASE] Phase2: v2ã§Adaptiveå¾©å…ƒ", flush=True)
    v2_url = f"{url}?v=v2"
    page = Fetcher.get(v2_url)
    html = page.html_content

    # BS4ã§v1ã‚»ãƒ¬ã‚¯ã‚¿ã‚’è©¦è¡Œ
    print("[STEP] BS4ã§v1ã‚»ãƒ¬ã‚¯ã‚¿ã‚’è©¦è¡Œ", flush=True)
    soup = BeautifulSoup(html, "html.parser")
    bs4_results = {}
    for css, label in SELECTORS:
        class_name = css.lstrip(".")
        count = len(soup.find_all(class_=class_name))
        bs4_results[label] = count
        status = f"âœ… {count}ä»¶" if count > 0 else "ğŸ’¥ 0ä»¶"
        print(f"[BS4] {label} ({css}) â†’ {status}", flush=True)
        current += 1
        print(f"[PROGRESS] {current}/{total}", flush=True)
        time.sleep(0.3)

    # Scrapling Adaptiveã§å¾©å…ƒ
    print("[STEP] Scrapling Adaptiveã§å¾©å…ƒ", flush=True)
    selector2 = Selector(
        html, url=url, adaptive=True,
        storage=SQLiteStorageSystem,
        storage_args={"storage_file": STORAGE_FILE, "url": url},
    )

    scrapling_results = {}
    for css, label in SELECTORS:
        found = selector2.css(css, adaptive=True)
        if found:
            el = found[0]
            scrapling_results[label] = {
                "text": el.text.strip(),
                "tag": el.tag,
                "class": el.attrib.get("class", ""),
                "original_selector": css,
                "status": "restored",
            }
            print(f"[RESTORE] {label} ({css}) â†’ âœ… ã€Œ{el.text.strip()}ã€", flush=True)
        else:
            scrapling_results[label] = {
                "status": "not_found",
                "original_selector": css,
            }
            print(f"[RESTORE] {label} ({css}) â†’ ğŸ’¥ å¾©å…ƒå¤±æ•—", flush=True)
        current += 1
        print(f"[PROGRESS] {current}/{total}", flush=True)
        time.sleep(0.4)

    # çµæœä¿å­˜
    print("[STEP] çµæœä¿å­˜", flush=True)
    result = {
        "v1_save": v1_results,
        "v2_bs4": bs4_results,
        "v2_scrapling": scrapling_results,
    }
    filepath = os.path.join(DATA_DIR, "adaptive_result.json")
    os.makedirs(os.path.dirname(filepath), exist_ok=True)
    with open(filepath, "w", encoding="utf-8") as f:
        json.dump(result, f, ensure_ascii=False, indent=2)
    current += 1
    print(f"[PROGRESS] {current}/{total}", flush=True)

    # ã‚µãƒãƒª
    bs4_found = sum(1 for v in bs4_results.values() if v > 0)
    scrapling_found = sum(
        1 for v in scrapling_results.values()
        if isinstance(v, dict) and v.get("status") == "restored"
    )
    print(f"[SUMMARY] BS4: {bs4_found}/{len(SELECTORS)}ä»¶ | Scrapling: {scrapling_found}/{len(SELECTORS)}ä»¶å¾©å…ƒ", flush=True)
    print("[DONE] Adaptive ãƒ•ãƒ«ãƒ‡ãƒ¢å®Œäº†", flush=True)

    return result


def main():
    realtime = "--realtime" in sys.argv
    args = [a for a in sys.argv[1:] if a != "--realtime"]

    if not args:
        print("ä½¿ã„æ–¹: python -m scraper.adaptive [phase1|phase2|full] [--realtime]")
        print("  phase1     - v1ã®HTMLã§æŒ‡ç´‹ã‚’ä¿å­˜")
        print("  phase2     - v2ã®HTMLã§Adaptiveå¾©å…ƒ")
        print("  full       - ãƒ•ãƒ«ãƒ‡ãƒ¢ï¼ˆã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚¯ãƒªã‚¢ â†’ v1ä¿å­˜ â†’ v2å¾©å…ƒ â†’ æ¯”è¼ƒï¼‰")
        print("  --realtime - ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡ºåŠ›ãƒ¢ãƒ¼ãƒ‰ï¼ˆãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰é€£æºç”¨ï¼‰")
        sys.exit(1)

    command = args[0]

    try:
        requests.get(f"{BASE_URL}/version")
    except requests.ConnectionError:
        if realtime:
            print("[ERROR] Flaskã‚µãƒ¼ãƒãƒ¼ãŒèµ·å‹•ã—ã¦ã„ã¾ã›ã‚“", flush=True)
        else:
            print("ã‚¨ãƒ©ãƒ¼: Flaskã‚µãƒ¼ãƒãƒ¼ãŒèµ·å‹•ã—ã¦ã„ã¾ã›ã‚“ã€‚å…ˆã« python3 demo_site/app.py ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        sys.exit(1)

    if command == "phase1":
        print("Phase 1: v1ã§æŒ‡ç´‹ä¿å­˜")
        phase1_save()
    elif command == "phase2":
        print("Phase 2: v2ã§Adaptiveå¾©å…ƒ")
        phase2_restore()
    elif command == "full":
        if realtime:
            run_full_demo_realtime()
        else:
            run_full_demo()
    else:
        print(f"ä¸æ˜ãªã‚³ãƒãƒ³ãƒ‰: {command}")
        sys.exit(1)


if __name__ == "__main__":
    main()
