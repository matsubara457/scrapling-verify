"""Streamlit ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ â€” Scrapling Price Tracker

å•†å“ãƒ‡ãƒ¼ã‚¿ã®å¯è¦–åŒ–ã€Adaptiveæ¯”è¼ƒã€ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å®Ÿè¡Œã‚’æä¾›ã™ã‚‹ã€‚
"""

import glob
import json
import os
import subprocess
import sys

import pandas as pd
import plotly.express as px
import streamlit as st

st.set_page_config(
    page_title="Scrapling Price Tracker",
    page_icon="ğŸ•·ï¸",
    layout="wide",
)

DATA_DIR = os.path.join(os.path.dirname(__file__), "..", "data")
PROJECT_ROOT = os.path.join(os.path.dirname(__file__), "..")


# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ ---
st.sidebar.title("ğŸ•·ï¸ Scrapling Price Tracker")
page = st.sidebar.radio(
    "ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³",
    ["ğŸ  æ¦‚è¦", "ğŸ“Š å•†å“ãƒ‡ãƒ¼ã‚¿", "ğŸ”„ Adaptiveæ¯”è¼ƒ", "âš¡ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å®Ÿè¡Œ"],
)


# ===== ğŸ  æ¦‚è¦ãƒšãƒ¼ã‚¸ =====
if page == "ğŸ  æ¦‚è¦":
    st.title("ğŸ•·ï¸ Scrapling Price Tracker")
    st.markdown("""
    **Scraplingã®ä¸»è¦æ©Ÿèƒ½ã‚’ãƒ‡ãƒ¢ã™ã‚‹ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³**ã§ã™ã€‚
    ãƒ­ãƒ¼ã‚«ãƒ«ã®ãƒ€ãƒŸãƒ¼ECã‚µã‚¤ãƒˆã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã—ã€å•†å“ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã§å¯è¦–åŒ–ã—ã¾ã™ã€‚
    """)

    st.subheader("ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£")
    st.code("""
    [Flask ãƒ€ãƒŸãƒ¼ã‚µã‚¤ãƒˆ]  â†’  [Scrapling ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼]  â†’  [JSON/CSV ãƒ•ã‚¡ã‚¤ãƒ«]
     localhost:5001            Fetcher + Parser              data/
                               Adaptiveæ©Ÿèƒ½
                                      â†“
                              [Streamlit ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰]
                               localhost:8501
    """, language="text")

    st.subheader("ä½¿ã„æ–¹")
    st.markdown("""
    1. **Flaskèµ·å‹•**: `python demo_site/app.py` (port 5001)
    2. **ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å®Ÿè¡Œ**: `python -m scraper.basic` ã¾ãŸã¯å³ã®ã€Œå®Ÿè¡Œã€ãƒšãƒ¼ã‚¸ã‹ã‚‰
    3. **ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã§ç¢ºèª**: ã“ã®ãƒšãƒ¼ã‚¸ã®å„ã‚¿ãƒ–ã‚’ç¢ºèª
    """)

    st.subheader("Scraplingã¨ã¯")
    st.markdown("""
    [Scrapling](https://github.com/D4Vinci/Scrapling) ã¯ GitHub â˜…17,700+ ã®Pythonè£½Webã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ã™ã€‚

    **ä¸»ãªç‰¹å¾´:**
    - **Adaptive Scraping**: ã‚µã‚¤ãƒˆã®æ§‹é€ ãŒå¤‰ã‚ã£ã¦ã‚‚è¦ç´ ã‚’è‡ªå‹•è¿½è·¡
    - **é«˜é€Ÿãƒ‘ãƒ¼ã‚µãƒ¼**: lxmlãƒ™ãƒ¼ã‚¹ã§é«˜é€ŸãªHTMLè§£æ
    - **find_similar()**: é¡ä¼¼è¦ç´ ã®è‡ªå‹•æ¤œå‡º
    - **Fetcher**: httpx/Playwright/Camoufoxã«ã‚ˆã‚‹æŸ”è»ŸãªHTTPå–å¾—
    """)


# ===== ğŸ“Š å•†å“ãƒ‡ãƒ¼ã‚¿ãƒšãƒ¼ã‚¸ =====
elif page == "ğŸ“Š å•†å“ãƒ‡ãƒ¼ã‚¿":
    st.title("ğŸ“Š å•†å“ãƒ‡ãƒ¼ã‚¿")

    json_files = sorted(glob.glob(os.path.join(DATA_DIR, "products_*.json")))

    if not json_files:
        st.warning("ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚å…ˆã«ã€Œâš¡ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å®Ÿè¡Œã€ãƒšãƒ¼ã‚¸ã§ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
    else:
        file_names = [os.path.basename(f) for f in json_files]
        selected = st.selectbox("ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹", file_names)
        selected_path = os.path.join(DATA_DIR, selected)

        with open(selected_path, "r", encoding="utf-8") as f:
            data = json.load(f)

        df = pd.DataFrame(data)
        st.subheader("å•†å“ä¸€è¦§")
        st.dataframe(df, use_container_width=True)

        col1, col2 = st.columns(2)

        with col1:
            st.subheader("ä¾¡æ ¼æ¯”è¼ƒ")
            if "name" in df.columns and "price" in df.columns:
                fig_bar = px.bar(
                    df, x="name", y="price",
                    title="å•†å“åˆ¥ä¾¡æ ¼",
                    labels={"name": "å•†å“å", "price": "ä¾¡æ ¼ (å††)"},
                    color="price",
                    color_continuous_scale="Blues",
                )
                fig_bar.update_layout(xaxis_tickangle=-45)
                st.plotly_chart(fig_bar, use_container_width=True)

        with col2:
            st.subheader("ã‚«ãƒ†ã‚´ãƒªåˆ¥å•†å“æ•°")
            if "category" in df.columns:
                category_counts = df["category"].value_counts().reset_index()
                category_counts.columns = ["category", "count"]
                fig_pie = px.pie(
                    category_counts, values="count", names="category",
                    title="ã‚«ãƒ†ã‚´ãƒªåˆ†å¸ƒ",
                )
                st.plotly_chart(fig_pie, use_container_width=True)

        # CSV DL
        csv_data = df.to_csv(index=False).encode("utf-8-sig")
        st.download_button(
            "ğŸ“¥ CSV ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=csv_data,
            file_name=selected.replace(".json", ".csv"),
            mime="text/csv",
        )


# ===== ğŸ”„ Adaptiveæ¯”è¼ƒãƒšãƒ¼ã‚¸ =====
elif page == "ğŸ”„ Adaptiveæ¯”è¼ƒ":
    st.title("ğŸ”„ Adaptive Scraping æ¯”è¼ƒ")

    adaptive_path = os.path.join(DATA_DIR, "adaptive_result.json")

    if not os.path.exists(adaptive_path):
        st.warning("AdaptiveçµæœãŒã‚ã‚Šã¾ã›ã‚“ã€‚å…ˆã«Adaptiveãƒ‡ãƒ¢ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        st.code("python -m scraper.adaptive full", language="bash")

        if st.button("ğŸ”„ Adaptive ãƒ•ãƒ«ãƒ‡ãƒ¢å®Ÿè¡Œ"):
            with st.spinner("Adaptive ãƒ•ãƒ«ãƒ‡ãƒ¢å®Ÿè¡Œä¸­..."):
                result = subprocess.run(
                    [sys.executable, "-m", "scraper.adaptive", "full"],
                    capture_output=True, text=True, cwd=PROJECT_ROOT,
                )
                if result.returncode == 0:
                    st.success("å®Ÿè¡Œå®Œäº†ï¼ãƒšãƒ¼ã‚¸ã‚’ãƒªãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
                    st.code(result.stdout)
                    st.rerun()
                else:
                    st.error("å®Ÿè¡Œã‚¨ãƒ©ãƒ¼")
                    st.code(result.stderr)
    else:
        with open(adaptive_path, "r", encoding="utf-8") as f:
            adaptive_data = json.load(f)

        # v1 â†’ v2 ã®å¤‰æ›´ç‚¹
        st.subheader("v1 â†’ v2 ã®å¤‰æ›´ç‚¹")
        changes = pd.DataFrame([
            {"è¦ç´ ": "å•†å“ã‚«ãƒ¼ãƒ‰", "v1ã‚»ãƒ¬ã‚¯ã‚¿": "div.product-card", "v2ã‚»ãƒ¬ã‚¯ã‚¿": "article.item-tile"},
            {"è¦ç´ ": "å•†å“å", "v1ã‚»ãƒ¬ã‚¯ã‚¿": "h2.product-name", "v2ã‚»ãƒ¬ã‚¯ã‚¿": "h3.title"},
            {"è¦ç´ ": "ä¾¡æ ¼", "v1ã‚»ãƒ¬ã‚¯ã‚¿": "span.product-price", "v2ã‚»ãƒ¬ã‚¯ã‚¿": "div.cost"},
            {"è¦ç´ ": "è©•ä¾¡", "v1ã‚»ãƒ¬ã‚¯ã‚¿": "div.product-rating", "v2ã‚»ãƒ¬ã‚¯ã‚¿": "div.stars"},
            {"è¦ç´ ": "ã‚«ãƒ†ã‚´ãƒª", "v1ã‚»ãƒ¬ã‚¯ã‚¿": "span.product-category", "v2ã‚»ãƒ¬ã‚¯ã‚¿": "span.tag"},
            {"è¦ç´ ": "èª¬æ˜", "v1ã‚»ãƒ¬ã‚¯ã‚¿": "p.product-desc", "v2ã‚»ãƒ¬ã‚¯ã‚¿": "p.desc"},
        ])
        st.table(changes)

        # BS4 vs Scrapling æ¯”è¼ƒ
        st.subheader("BS4 vs Scraplingï¼ˆv2ã®HTMLã«v1ã‚»ãƒ¬ã‚¯ã‚¿ã‚’é©ç”¨ï¼‰")

        v2_bs4 = adaptive_data.get("v2_bs4", {})
        v2_scrapling = adaptive_data.get("v2_scrapling", {})

        comparison_rows = []
        for label in ["å•†å“å", "ä¾¡æ ¼", "è©•ä¾¡", "ã‚«ãƒ†ã‚´ãƒª", "èª¬æ˜"]:
            bs4_count = v2_bs4.get(label, 0)
            scr_data = v2_scrapling.get(label, {})
            scr_status = scr_data.get("status", "not_found") if isinstance(scr_data, dict) else "not_found"
            scr_text = scr_data.get("text", "-") if isinstance(scr_data, dict) else "-"
            comparison_rows.append({
                "ã‚»ãƒ¬ã‚¯ã‚¿": label,
                "BS4 (v2)": f"ğŸ’¥ {bs4_count}ä»¶" if bs4_count == 0 else f"âœ… {bs4_count}ä»¶",
                "Scrapling": f"âœ… {scr_text}" if scr_status == "restored" else "ğŸ’¥ å¾©å…ƒå¤±æ•—",
            })

        st.table(pd.DataFrame(comparison_rows))

        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹
        col1, col2 = st.columns(2)
        bs4_total = sum(v for v in v2_bs4.values() if isinstance(v, int))
        scrapling_restored = sum(
            1 for v in v2_scrapling.values()
            if isinstance(v, dict) and v.get("status") == "restored"
        )

        with col1:
            st.metric("BS4 (v1ã‚»ãƒ¬ã‚¯ã‚¿ â†’ v2)", f"ğŸ’¥ {bs4_total}ä»¶", delta=None)
        with col2:
            st.metric("Scrapling Adaptive", f"âœ… {scrapling_restored}ä»¶å¾©å…ƒ", delta=None)

        # å¾©å…ƒè©³ç´°
        st.subheader("å¾©å…ƒè©³ç´°")
        for label, data in v2_scrapling.items():
            if isinstance(data, dict):
                with st.expander(f"{label} ({data.get('original_selector', '')})"):
                    st.json(data)

        # å†å®Ÿè¡Œãƒœã‚¿ãƒ³
        st.divider()
        st.subheader("ãƒ‡ãƒ¢å†å®Ÿè¡Œ")
        btn_col1, btn_col2, btn_col3 = st.columns(3)

        with btn_col1:
            if st.button("ğŸ“Œ Phase1: v1ã§ä¿å­˜"):
                with st.spinner("Phase1 å®Ÿè¡Œä¸­..."):
                    result = subprocess.run(
                        [sys.executable, "-m", "scraper.adaptive", "phase1"],
                        capture_output=True, text=True, cwd=PROJECT_ROOT,
                    )
                    if result.returncode == 0:
                        st.success("Phase1 å®Œäº†ï¼")
                        st.code(result.stdout)
                    else:
                        st.error("Phase1 ã‚¨ãƒ©ãƒ¼")
                        st.code(result.stderr)

        with btn_col2:
            if st.button("ğŸ”„ Phase2: v2ã§å¾©å…ƒ"):
                with st.spinner("Phase2 å®Ÿè¡Œä¸­..."):
                    result = subprocess.run(
                        [sys.executable, "-m", "scraper.adaptive", "phase2"],
                        capture_output=True, text=True, cwd=PROJECT_ROOT,
                    )
                    if result.returncode == 0:
                        st.success("Phase2 å®Œäº†ï¼")
                        st.code(result.stdout)
                    else:
                        st.error("Phase2 ã‚¨ãƒ©ãƒ¼")
                        st.code(result.stderr)

        with btn_col3:
            if st.button("âš¡ ãƒ•ãƒ«ãƒ‡ãƒ¢å†å®Ÿè¡Œ"):
                with st.spinner("Adaptive ãƒ•ãƒ«ãƒ‡ãƒ¢å®Ÿè¡Œä¸­..."):
                    result = subprocess.run(
                        [sys.executable, "-m", "scraper.adaptive", "full"],
                        capture_output=True, text=True, cwd=PROJECT_ROOT,
                    )
                    if result.returncode == 0:
                        st.success("ãƒ•ãƒ«ãƒ‡ãƒ¢å®Œäº†ï¼")
                        st.code(result.stdout)
                        st.rerun()
                    else:
                        st.error("ãƒ•ãƒ«ãƒ‡ãƒ¢ã‚¨ãƒ©ãƒ¼")
                        st.code(result.stderr)


# ===== âš¡ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å®Ÿè¡Œãƒšãƒ¼ã‚¸ =====
elif page == "âš¡ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å®Ÿè¡Œ":
    st.title("âš¡ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å®Ÿè¡Œ")
    st.markdown("ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ã®å‡¦ç†éç¨‹ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§å¯è¦–åŒ–ã—ã¾ã™ã€‚")

    url = st.text_input("å¯¾è±¡URL", value="http://localhost:5001")

    col1, col2, col3 = st.columns(3)

    with col1:
        basic_clicked = st.button("ğŸ•·ï¸ åŸºæœ¬ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°", use_container_width=True)
    with col2:
        adaptive_clicked = st.button("ğŸ”„ Adaptive ãƒ•ãƒ«ãƒ‡ãƒ¢", use_container_width=True)
    with col3:
        visual_clicked = st.button("ğŸ‘ï¸ ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«å®Ÿè¡Œ", use_container_width=True)

    if visual_clicked:
        st.info("ğŸ–¥ï¸ ãƒ–ãƒ©ã‚¦ã‚¶ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ãŒé–‹ãã¾ã™ã€‚ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã®æ§˜å­ã‚’è¦³å¯Ÿã—ã¦ãã ã•ã„ã€‚")
        progress_bar = st.progress(0, text="ãƒ–ãƒ©ã‚¦ã‚¶èµ·å‹•ä¸­...")
        status = st.status("ğŸ‘ï¸ ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å®Ÿè¡Œä¸­...", expanded=True)
        table_container = st.empty()

        env = {**os.environ, "PYTHONUNBUFFERED": "1"}
        proc = subprocess.Popen(
            [sys.executable, "-m", "scraper.visual", "--realtime"],
            stdout=subprocess.PIPE, stderr=subprocess.PIPE,
            text=True, cwd=PROJECT_ROOT, env=env,
        )

        products = []
        done = False

        for line in iter(proc.stdout.readline, ""):
            line = line.rstrip()
            if not line:
                continue

            if line.startswith("[STEP]"):
                status.write(f"â³ {line.replace('[STEP] ', '')}")
            elif line.startswith("[INFO]"):
                status.write(f"â„¹ï¸ {line.replace('[INFO] ', '')}")
            elif line.startswith("[PRODUCT]"):
                product = json.loads(line.replace("[PRODUCT] ", ""))
                products.append(product)
                table_container.dataframe(
                    pd.DataFrame(products), use_container_width=True,
                )
            elif line.startswith("[PROGRESS]"):
                parts = line.replace("[PROGRESS] ", "").split("/")
                current, total = int(parts[0]), int(parts[1])
                if total > 0:
                    progress_bar.progress(current / total, text=f"é€²æ—: {current}/{total}")
            elif line.startswith("[DONE]"):
                progress_bar.progress(1.0, text="å®Œäº†!")
                status.update(label=f"âœ… {line.replace('[DONE] ', '')}", state="complete")
                done = True
            elif line.startswith("[WARN]"):
                status.write(f"âš ï¸ {line.replace('[WARN] ', '')}")
            elif line.startswith("[ERROR]"):
                status.update(label=f"âŒ {line.replace('[ERROR] ', '')}", state="error")

        proc.wait()

        if proc.returncode != 0 and not done:
            error_output = proc.stderr.read()
            if error_output:
                status.update(label="âŒ å®Ÿè¡Œã‚¨ãƒ©ãƒ¼", state="error")
                st.error("ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
                st.code(error_output)

    if basic_clicked or adaptive_clicked:
        if basic_clicked:
            cmd = [sys.executable, "-m", "scraper.basic", "--realtime"]
            scraper_label = "åŸºæœ¬ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°"
        else:
            cmd = [sys.executable, "-m", "scraper.adaptive", "full", "--realtime"]
            scraper_label = "Adaptive ãƒ•ãƒ«ãƒ‡ãƒ¢"

        # UI ã‚³ãƒ³ãƒ†ãƒŠã‚’é…ç½®
        progress_bar = st.progress(0, text="æº–å‚™ä¸­...")
        status = st.status(f"ğŸ”´ {scraper_label} å®Ÿè¡Œä¸­...", expanded=True)
        table_container = st.empty()

        # subprocess.Popen ã§ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ èª­ã¿å–ã‚Š
        env = {**os.environ, "PYTHONUNBUFFERED": "1"}
        proc = subprocess.Popen(
            cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE,
            text=True, cwd=PROJECT_ROOT, env=env,
        )

        products = []
        done = False

        for line in iter(proc.stdout.readline, ""):
            line = line.rstrip()
            if not line:
                continue

            if line.startswith("[STEP]"):
                step_text = line.replace("[STEP] ", "")
                status.write(f"â³ {step_text}")
            elif line.startswith("[PHASE]"):
                phase_text = line.replace("[PHASE] ", "")
                status.write(f"ğŸ”„ **{phase_text}**")
            elif line.startswith("[INFO]"):
                info_text = line.replace("[INFO] ", "")
                status.write(f"â„¹ï¸ {info_text}")
            elif line.startswith("[PRODUCT]"):
                json_str = line.replace("[PRODUCT] ", "")
                product = json.loads(json_str)
                products.append(product)
                table_container.dataframe(
                    pd.DataFrame(products), use_container_width=True,
                )
            elif line.startswith("[SAVE]"):
                save_text = line.replace("[SAVE] ", "")
                status.write(f"ğŸ’¾ ä¿å­˜: {save_text}")
            elif line.startswith("[BS4]"):
                bs4_text = line.replace("[BS4] ", "")
                status.write(f"ğŸ” BS4: {bs4_text}")
            elif line.startswith("[RESTORE]"):
                restore_text = line.replace("[RESTORE] ", "")
                status.write(f"âœ¨ å¾©å…ƒ: {restore_text}")
            elif line.startswith("[MISS]"):
                miss_text = line.replace("[MISS] ", "")
                status.write(f"âš ï¸ {miss_text}")
            elif line.startswith("[PROGRESS]"):
                parts = line.replace("[PROGRESS] ", "").split("/")
                current, total = int(parts[0]), int(parts[1])
                pct = current / total
                progress_bar.progress(pct, text=f"é€²æ—: {current}/{total}")
            elif line.startswith("[SUMMARY]"):
                summary_text = line.replace("[SUMMARY] ", "")
                status.write(f"ğŸ“Š **{summary_text}**")
            elif line.startswith("[DONE]"):
                done_text = line.replace("[DONE] ", "")
                progress_bar.progress(1.0, text="å®Œäº†!")
                status.update(label=f"âœ… {done_text}", state="complete")
                done = True
            elif line.startswith("[WARN]"):
                warn_text = line.replace("[WARN] ", "")
                status.write(f"âš ï¸ {warn_text}")
            elif line.startswith("[ERROR]"):
                error_text = line.replace("[ERROR] ", "")
                status.update(label=f"âŒ {error_text}", state="error")

        proc.wait()

        if proc.returncode != 0 and not done:
            error_output = proc.stderr.read()
            if error_output:
                status.update(label="âŒ å®Ÿè¡Œã‚¨ãƒ©ãƒ¼", state="error")
                st.error("ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
                st.code(error_output)

        # å®Œäº†å¾Œã®ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆåŸºæœ¬ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã®å ´åˆï¼‰
        if done and basic_clicked:
            json_files = sorted(glob.glob(os.path.join(DATA_DIR, "products_*.json")))
            if json_files:
                latest = json_files[-1]
                with open(latest, "r", encoding="utf-8") as f:
                    preview_data = json.load(f)
                st.subheader("ğŸ“Š å–å¾—ãƒ‡ãƒ¼ã‚¿ã‚µãƒãƒª")
                df = pd.DataFrame(preview_data)
                col_a, col_b = st.columns(2)
                with col_a:
                    st.metric("å–å¾—ä»¶æ•°", f"{len(df)}ä»¶")
                with col_b:
                    if "price" in df.columns:
                        st.metric("å¹³å‡ä¾¡æ ¼", f"Â¥{df['price'].mean():,.0f}")
