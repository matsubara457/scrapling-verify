# 01. 要件定義書 — Scrapling Price Tracker

## プロダクト概要

| 項目 | 内容 |
|------|------|
| プロダクト名 | Scrapling Price Tracker |
| 概要 | ローカルのダミーECサイトをScraplingでスクレイピングし、商品データをStreamlitダッシュボードで可視化するデモアプリ |
| 目的 | ① Scraplingの各機能（Adaptive/Fetcher/Parser）を実践的に検証する ② Qiita記事の素材（コード＋スクリーンショット）を得る |
| ターゲット | Qiita読者（Pythonエンジニア全般） |
| 規模 | MVP（1〜2日で完成） |
| デプロイ | ローカルのみ |

## データフロー

```
┌──────────────────────────┐
│  ダミーECサイト (Flask)   │  ← v1/v2 UI切替 + CSV DL機能
│  http://localhost:5001    │
└───────────┬──────────────┘
            │ Scrapling (Fetcher + Parser)
            ▼
┌──────────────────────────┐
│  JSON/CSV ファイル保存     │  ← data/ ディレクトリ
│  (スクレイピング結果)      │
└───────────┬──────────────┘
            │ pandas で読み込み
            ▼
┌──────────────────────────┐
│  ダッシュボード (Streamlit)│  ← 可視化・比較・CSV出力
│  http://localhost:8501    │
└──────────────────────────┘
```

## 機能要件（MoSCoW）

### Must（必須）

| ID | 機能 | 説明 |
|----|------|------|
| F-SITE-001 | ダミーECサイト表示 | 商品一覧ページをFlaskで配信。6商品以上 |
| F-SITE-002 | UI v1/v2 切替 | `/switch` でHTML構造（class名・タグ名）を大幅変更 |
| F-SITE-003 | CSV DLエンドポイント | `/csv` で商品一覧をCSVダウンロード |
| F-SCRAPE-001 | 基本スクレイピング | Scrapling Fetcherでダミーサイトから商品データを取得 |
| F-SCRAPE-002 | Adaptive保存 | `auto_save=True` で要素の指紋をローカルに保存 |
| F-SCRAPE-003 | Adaptive復元 | `adaptive=True` でv2構造から要素を自動復元 |
| F-SCRAPE-004 | 結果ファイル保存 | スクレイピング結果をJSON/CSVで `data/` に保存 |
| F-SCRAPE-007 | ビジュアルスクレイピング | Playwright でブラウザ表示しながらスクレイピング過程を可視化 |
| F-DASH-001 | 商品一覧テーブル | スクレイピング結果を表形式で表示 |
| F-DASH-002 | 価格グラフ | 商品価格の棒グラフ・カテゴリ別集計 |
| F-DASH-003 | CSV DL（ダッシュボード側） | 表示データをCSVでダウンロード |

### Should（できれば）

| ID | 機能 | 説明 |
|----|------|------|
| F-SCRAPE-005 | BS4比較デモ | 同じHTML対してBS4とScraplingの結果を並べて比較 |
| F-SCRAPE-006 | find_similar デモ | 1要素から類似要素を自動発見する実演 |
| F-DASH-004 | Adaptive比較ビュー | v1→v2での「BS4: 0件 vs Scrapling: 復元」を可視化 |
| F-DASH-005 | スクレイピング実行ボタン | ダッシュボードから基本/Adaptive/ビジュアルの3種を実行 |
| F-DASH-006 | リアルタイム進捗表示 | スクレイピング実行中のプログレスバー・ステータス・ストリーミング出力 |

### Won't（今回やらない）

- 定期実行（cron / スケジューラ）
- 外部サイト対応
- ユーザー認証
- デプロイ・Docker化
- DB（SQLite / PostgreSQL）※ Adaptive指紋保存用のSQLiteは使用
- Spider フレームワーク

## 非機能要件

| 項目 | 基準 |
|------|------|
| パフォーマンス | ローカル完結のため特に制約なし |
| 可用性 | ローカルのみ・デモ用 |
| セキュリティ | ローカルのみ・認証不要 |
| 再現性 | Qiita読者が `pip install` → 即動かせること |
| ドキュメント | 全手順をMDファイルで記録（記事の素材） |

## 用語集

| 用語 | 定義 |
|------|------|
| ダミーサイト | Flaskで構築するスクレイピング対象のローカルECサイト |
| v1 | ダミーサイトの初期デザイン（元のclass名・構造） |
| v2 | ダミーサイトのリニューアルデザイン（class名・タグ名・構造が全変更） |
| Adaptive | Scraplingの要素追跡機能。auto_saveで指紋保存、adaptive=Trueで復元 |
| 指紋 | 要素のタグ名・テキスト・属性・親・兄弟の構造情報（SQLiteに保存） |
| ダッシュボード | Streamlitで構築するデータ可視化画面 |
