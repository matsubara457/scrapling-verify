# 03. æŠ€è¡“è¨­è¨ˆæ›¸ â€” Scrapling Price Tracker

## æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯

| ã‚«ãƒ†ã‚´ãƒª | æŠ€è¡“ | ãƒãƒ¼ã‚¸ãƒ§ãƒ³ | ç”¨é€” |
|---------|------|-----------|------|
| ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚° | Scrapling | 0.4+ | ãƒ‘ãƒ¼ã‚µãƒ¼ + Fetcher + Adaptive |
| æ¯”è¼ƒç”¨ | BeautifulSoup4 | 4.12+ | Adaptiveæ¯”è¼ƒãƒ‡ãƒ¢ |
| ãƒ€ãƒŸãƒ¼ã‚µã‚¤ãƒˆ | Flask | 3.0+ | ãƒ­ãƒ¼ã‚«ãƒ«ECã‚µã‚¤ãƒˆ |
| ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ | Streamlit | 1.40+ | ãƒ‡ãƒ¼ã‚¿å¯è¦–åŒ– |
| ãƒ‡ãƒ¼ã‚¿å‡¦ç† | pandas | 2.2+ | CSV/JSONèª­ã¿æ›¸ã + é›†è¨ˆ |
| ã‚°ãƒ©ãƒ• | plotly | 5.24+ | ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ã‚°ãƒ©ãƒ• |
| ãƒ‡ãƒ¼ã‚¿ä¿å­˜ | JSON / CSV ãƒ•ã‚¡ã‚¤ãƒ« | - | data/ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª |
| Python | Python | 3.10+ | Scraplingæœ€å°è¦ä»¶ |

## ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹æˆ

```
scrapling-price-tracker/
â”œâ”€â”€ demo_site/
â”‚   â”œâ”€â”€ app.py                 # Flask ãƒ€ãƒŸãƒ¼ECã‚µã‚¤ãƒˆï¼ˆv1/v2åˆ‡æ›¿ + CSV DLï¼‰
â”‚   â”œâ”€â”€ templates/
â”‚   â”‚   â”œâ”€â”€ v1.html            # v1ãƒ‡ã‚¶ã‚¤ãƒ³
â”‚   â”‚   â””â”€â”€ v2.html            # v2ãƒ‡ã‚¶ã‚¤ãƒ³ï¼ˆæ§‹é€ å¤‰æ›´å¾Œï¼‰
â”‚   â””â”€â”€ data/
â”‚       â””â”€â”€ products.json      # å•†å“ãƒã‚¹ã‚¿ãƒ‡ãƒ¼ã‚¿
â”‚
â”œâ”€â”€ scraper/
â”‚   â”œâ”€â”€ basic.py               # F-SCRAPE-001: åŸºæœ¬ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚° + ä¿å­˜
â”‚   â”œâ”€â”€ adaptive.py            # F-SCRAPE-002/003: Adaptiveä¿å­˜ + å¾©å…ƒ
â”‚   â”œâ”€â”€ comparison.py          # F-SCRAPE-005: BS4 vs Scraplingæ¯”è¼ƒ
â”‚   â””â”€â”€ similarity.py          # F-SCRAPE-006: find_similar ãƒ‡ãƒ¢
â”‚
â”œâ”€â”€ dashboard/
â”‚   â””â”€â”€ app.py                 # Streamlit ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ï¼ˆå…¨F-DASHæ©Ÿèƒ½ï¼‰
â”‚
â”œâ”€â”€ data/                      # ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°çµæœã®å‡ºåŠ›å…ˆ
â”‚   â”œâ”€â”€ products_v1.json       # v1ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°çµæœ
â”‚   â”œâ”€â”€ products_v2.json       # v2ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°çµæœ
â”‚   â””â”€â”€ adaptive_result.json   # Adaptiveå¾©å…ƒçµæœ
â”‚
â”œâ”€â”€ docs/                      # è¨­è¨ˆãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆï¼ˆæœ¬ãƒ•ã‚¡ã‚¤ãƒ«ç¾¤ï¼‰
â”‚
â”œâ”€â”€ requirements.txt           # pipä¾å­˜
â”œâ”€â”€ README.md                  # ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—æ‰‹é †
â””â”€â”€ run.sh                     # ä¸€æ‹¬èµ·å‹•ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
```

## ãƒ€ãƒŸãƒ¼ã‚µã‚¤ãƒˆè¨­è¨ˆï¼ˆFlaskï¼‰

### å•†å“ãƒ‡ãƒ¼ã‚¿å®šç¾©

```python
# demo_site/data/products.json
[
  {
    "id": 1,
    "name": "ãƒ¯ã‚¤ãƒ¤ãƒ¬ã‚¹ã‚¤ãƒ¤ãƒ›ãƒ³ Pro",
    "price": 12800,
    "category": "ã‚ªãƒ¼ãƒ‡ã‚£ã‚ª",
    "rating": 4.5,
    "reviews": 128,
    "description": "ãƒã‚¤ã‚ºã‚­ãƒ£ãƒ³ã‚»ãƒªãƒ³ã‚°æ­è¼‰ã®é«˜éŸ³è³ªãƒ¯ã‚¤ãƒ¤ãƒ¬ã‚¹ã‚¤ãƒ¤ãƒ›ãƒ³ã€‚æœ€å¤§30æ™‚é–“å†ç”Ÿã€‚"
  },
  // ... è¨ˆ6å•†å“
]
```

### ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ

| Method | Path | èª¬æ˜ |
|--------|------|------|
| GET | `/` | å•†å“ä¸€è¦§ï¼ˆv1 or v2ï¼‰ |
| GET | `/switch` | v1â‡”v2ã‚’åˆ‡æ›¿ã—ã¦ãƒªãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆ |
| GET | `/csv` | å•†å“ä¸€è¦§CSVã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ |
| GET | `/api/products` | å•†å“ä¸€è¦§JSONï¼ˆç¢ºèªç”¨ï¼‰ |
| GET | `/version` | ç¾åœ¨ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³(v1/v2)ã‚’è¿”ã™ |

### v1 â†’ v2 å¤‰æ›´å¯¾å¿œè¡¨

| è¦ç´  | v1ï¼ˆã‚»ãƒ¬ã‚¯ã‚¿ï¼‰ | v2ï¼ˆã‚»ãƒ¬ã‚¯ã‚¿ï¼‰ |
|------|--------------|--------------|
| å•†å“ã‚«ãƒ¼ãƒ‰ | `div.product-card` | `article.item-tile` |
| å•†å“å | `h2.product-name` | `h3.title` |
| ä¾¡æ ¼ | `span.product-price` | `div.cost` |
| è©•ä¾¡ | `div.product-rating` | `div.stars` |
| ã‚«ãƒ†ã‚´ãƒª | `span.product-category` | `span.tag` |
| èª¬æ˜ | `p.product-desc` | `p.desc` |
| IDå±æ€§ | `data-id` | `data-product-id` |
| è¦ªã‚³ãƒ³ãƒ†ãƒŠ | `div.product-list` | `div.catalog` |
| ãƒ˜ãƒƒãƒ€ãƒ¼ | `div.header > h1` | `nav.site-nav > span.logo` |

## ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼è¨­è¨ˆ

### basic.py â€” åŸºæœ¬ãƒ•ãƒ­ãƒ¼

```python
from scrapling.fetchers import Fetcher
import json

def scrape_products(url: str = "http://localhost:5001") -> list[dict]:
    """å•†å“ä¸€è¦§ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã—ã¦è¾æ›¸ãƒªã‚¹ãƒˆã§è¿”ã™"""
    page = Fetcher.get(url)

    # v1ã‚»ãƒ¬ã‚¯ã‚¿ã§è©¦è¡Œ â†’ å¤±æ•—ã—ãŸã‚‰v2ã‚»ãƒ¬ã‚¯ã‚¿ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    cards = page.css(".product-card")
    if not cards:
        cards = page.css(".item-tile")

    products = []
    for card in cards:
        products.append({
            "name": card.css("h2::text, h3::text").get(),
            "price": (card.css(".product-price::text, .cost::text").get() or "").replace("Â¥", "").replace(",", ""),
            "category": card.css(".product-category::text, .tag::text").get(),
            "rating": card.css(".product-rating::text, .stars::text").get(),
        })
    return products

def save_results(products: list[dict], filepath: str) -> None:
    """çµæœã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
    with open(filepath, "w", encoding="utf-8") as f:
        json.dump(products, f, ensure_ascii=False, indent=2)
```

### adaptive.py â€” Adaptive ãƒ•ãƒ­ãƒ¼

```python
from scrapling.parser import Selector
from scrapling.fetchers import Fetcher
import json, os, shutil

SELECTORS = [
    (".product-name", "å•†å“å"),
    (".product-price", "ä¾¡æ ¼"),
    (".product-rating", "è©•ä¾¡"),
    (".product-category", "ã‚«ãƒ†ã‚´ãƒª"),
    (".product-desc", "èª¬æ˜"),
]

def phase1_save(url: str = "http://localhost:5001") -> dict:
    """v1ã®HTMLã§è¦ç´ ã®æŒ‡ç´‹ã‚’ä¿å­˜"""
    page = Fetcher.get(url)
    html = page.html_content
    selector = Selector(html, url=url, adaptive=True)
    results = {}
    for css, label in SELECTORS:
        found = selector.css(css, auto_save=True)
        results[label] = found[0].text if found else None
    return results

def phase2_restore(url: str = "http://localhost:5001") -> dict:
    """v2ã®HTMLã§adaptiveã«ã‚ˆã‚Šå¾©å…ƒ"""
    page = Fetcher.get(url)
    html = page.html_content
    selector = Selector(html, url=url, adaptive=True)
    results = {}
    for css, label in SELECTORS:
        found = selector.css(css, adaptive=True)
        if found:
            el = found[0]
            results[label] = {
                "text": el.text,
                "tag": el.tag,
                "class": el.attrib.get("class", ""),
                "original_selector": css,
                "status": "restored"
            }
        else:
            results[label] = {"status": "not_found", "original_selector": css}
    return results
```

### comparison.py â€” BS4æ¯”è¼ƒ

```python
from bs4 import BeautifulSoup
from scrapling.parser import Selector

def compare(html: str) -> dict:
    """åŒã˜HTMLã«å¯¾ã—ã¦BS4ã¨Scraplingã®çµæœã‚’æ¯”è¼ƒ"""
    bs4_results = {}
    scraping_results = {}

    # BS4
    soup = BeautifulSoup(html, "html.parser")
    bs4_results["product-name"] = len(soup.find_all(class_="product-name"))
    bs4_results["product-price"] = len(soup.find_all(class_="product-price"))

    # Scrapling
    page = Selector(html)
    scraping_results["product-name"] = len(page.css(".product-name"))
    scraping_results["product-price"] = len(page.css(".product-price"))

    return {"bs4": bs4_results, "scrapling": scraping_results}
```

## ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰è¨­è¨ˆï¼ˆStreamlitï¼‰

### ãƒšãƒ¼ã‚¸æ§‹æˆ

```
ã‚µã‚¤ãƒ‰ãƒãƒ¼:
  - ğŸ  æ¦‚è¦
  - ğŸ“Š å•†å“ãƒ‡ãƒ¼ã‚¿
  - ğŸ”„ Adaptiveæ¯”è¼ƒ
  - âš¡ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å®Ÿè¡Œ

ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢:
  é¸æŠã•ã‚ŒãŸãƒšãƒ¼ã‚¸ã®å†…å®¹ã‚’è¡¨ç¤º
```

### å„ãƒšãƒ¼ã‚¸ã®è¡¨ç¤ºå†…å®¹

| ãƒšãƒ¼ã‚¸ | æ©Ÿèƒ½ID | å†…å®¹ |
|--------|--------|------|
| æ¦‚è¦ | - | ã‚¢ãƒ—ãƒªèª¬æ˜ãƒ»ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£å›³ãƒ»ä½¿ã„æ–¹ |
| å•†å“ãƒ‡ãƒ¼ã‚¿ | F-DASH-001,002,003 | ãƒ†ãƒ¼ãƒ–ãƒ« + æ£’ã‚°ãƒ©ãƒ• + ã‚«ãƒ†ã‚´ãƒªåˆ¥é›†è¨ˆ + CSV DL |
| Adaptiveæ¯”è¼ƒ | F-DASH-004 | v1/v2ã®BS4 vs Scraplingçµæœã‚’ä¸¦ã¹ã¦è¡¨ç¤º |
| ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å®Ÿè¡Œ | F-DASH-005 | ãƒœã‚¿ãƒ³æŠ¼ä¸‹ã§ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å®Ÿè¡Œ â†’ çµæœã‚’ãƒªãƒ­ãƒ¼ãƒ‰ |

### Streamlit ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆå¯¾å¿œ

| è¡¨ç¤ºè¦ç´  | Streamlitã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ |
|---------|----------------------|
| å•†å“ãƒ†ãƒ¼ãƒ–ãƒ« | `st.dataframe()` |
| ä¾¡æ ¼æ£’ã‚°ãƒ©ãƒ• | `st.plotly_chart()` (px.bar) |
| ã‚«ãƒ†ã‚´ãƒªåˆ¥é›†è¨ˆ | `st.plotly_chart()` (px.pie) |
| CSV DLãƒœã‚¿ãƒ³ | `st.download_button()` |
| ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å®Ÿè¡Œ | `st.button()` â†’ subprocess |
| Adaptiveæ¯”è¼ƒè¡¨ | `st.columns()` + `st.metric()` |
| ã‚»ãƒ¬ã‚¯ã‚¿å¾©å…ƒçµæœ | `st.json()` or `st.table()` |

## ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°

| çŠ¶æ³ | å¯¾å‡¦ |
|------|------|
| ãƒ€ãƒŸãƒ¼ã‚µã‚¤ãƒˆæœªèµ·å‹• | Streamlitã«ã€ŒFlaskèµ·å‹•ã—ã¦ãã ã•ã„ã€ã¨ã‚¨ãƒ©ãƒ¼è¡¨ç¤º |
| data/ã«ãƒ•ã‚¡ã‚¤ãƒ«ãªã— | ã€Œå…ˆã«ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€ã¨è¡¨ç¤º |
| Adaptiveã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ãªã— | ã€ŒPhase1(ä¿å­˜)ã‚’å…ˆã«å®Ÿè¡Œã—ã¦ãã ã•ã„ã€ã¨è¡¨ç¤º |
| ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å¤±æ•— | ã‚¨ãƒ©ãƒ¼å†…å®¹ã‚’Streamlitã«è¡¨ç¤º |
